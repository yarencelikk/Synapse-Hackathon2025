import google.generativeai as genai
from langchain_core.messages import HumanMessage, AIMessage
from app.agents.state import AgentState
from app.services import vector_store_manager
from app.core.config import settings

genai.configure(api_key=settings.GOOGLE_API_KEY)
llm = genai.GenerativeModel('gemini-2.5-flash')

def format_chat_history(messages: list) -> str:
    """Sohbet geÃ§miÅŸini LLM'in anlayacaÄŸÄ± basit bir metin formatÄ±na dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r."""
    if not messages:
        return ""
    # Son kullanÄ±cÄ± sorusu hariÃ§ geÃ§miÅŸi formatla
    history_str = "\n".join([f"{'KullanÄ±cÄ±' if isinstance(msg, HumanMessage) else 'Asistan'}: {msg.content}" for msg in messages[:-1]])
    return f"Ã–nceki KonuÅŸma GeÃ§miÅŸi:\n{history_str}\n"

def format_context(docs: list) -> str:
    return "\n\n---\n\n".join([doc['content'] for doc in docs])

def retrieve_documents(state: AgentState) -> dict:
    print("---DÃœÄÃœM: Belgeler Geri Getiriliyor---")
    # En son kullanÄ±cÄ± mesajÄ±nÄ± al
    query = state["messages"][-1].content
    classroom_id = state["classroom_id"]
    collection_name = f"classroom_{classroom_id}"
    agent_type = state.get("agent_type")

    if agent_type in ["summarizer", "simulation", "mind_mapper"]: n_results = 15
    else: n_results = 5
        
    retrieved_docs = vector_store_manager.query_vector_store(collection_name, query, n_results=n_results)
    print(f"{len(retrieved_docs)} adet ilgili belge parÃ§asÄ± bulundu.")
    
    return {"retrieved_docs": retrieved_docs, "query": query}

# --- Ajan DÃ¼ÄŸÃ¼mleri (Prompt'lar GÃ¼ncellendi) ---

def base_agent_node(state: AgentState, prompt_template: str) -> dict:
    """TÃ¼m ajanlar iÃ§in ortak bir temel fonksiyon."""
    print(f"---DÃœÄÃœM: {state.get('agent_type')} AjanÄ±---")
    
    chat_history = format_chat_history(state["messages"])
    query = state["query"]
    retrieved_docs = state["retrieved_docs"]

    if not retrieved_docs:
        return {"messages": [AIMessage(content="Bu konu hakkÄ±nda iÅŸlem yapmak iÃ§in yeterli belge bilgisi bulamadÄ±m.")]}

    context = format_context(retrieved_docs)
    
    prompt = prompt_template.format(chat_history=chat_history, context=context, query=query)
    
    response = llm.generate_content(prompt)
    # CevabÄ± AIMessage olarak dÃ¶ndÃ¼rerek LangGraph'in geÃ§miÅŸe eklemesini saÄŸlÄ±yoruz.
    return {"messages": [AIMessage(content=response.text)]}

# --- Her Ajan Ä°Ã§in Prompt ÅablonlarÄ± ---

direct_answer_prompt = """{chat_history}
Sen, yalnÄ±zca sana saÄŸlanan belgelere dayanarak sorularÄ± yanÄ±tlayan bir uzmansÄ±n. CevabÄ±n Ã¶ncelikli olarak bu belgelere dayanmalÄ±dÄ±r.

- Ã–ncelikle, sadece yukarÄ±daki BELGELER'de verilen bilgilerle soruyu eksiksiz ve aÃ§Ä±k bir ÅŸekilde yanÄ±tla.
- EÄŸer aranan bilgi BELGELER'de yer almÄ±yorsa, cevabÄ±na ÅŸu cÃ¼mleyle baÅŸla:  
"AradÄ±ÄŸÄ±nÄ±z bilgiyi saÄŸlanan belgede bulamadÄ±m. Ancak gÃ¼ncel internet kaynaklarÄ±na ve kendi bilgi birikimime gÃ¶re ÅŸÃ¶yle bir yanÄ±t verebilirim:"
- ArdÄ±ndan, kendi bilgi ve analizine dayanarak soruyu en iyi ÅŸekilde yanÄ±tla.
- CevabÄ±n, anlaÅŸÄ±lÄ±r ve gÃ¼ven verici bir dille, gerektiÄŸinde gerekÃ§esiyle birlikte olmalÄ±dÄ±r.

BELGELER:
{context}
SON KULLANICI SORUSU:
{query}
CEVAP:
"""

socratic_questioner_prompt = """{chat_history}
Sen bir Sokratik Ã¶ÄŸretmensin. GÃ¶revin, kullanÄ±cÄ±nÄ±n son sorusunu doÄŸrudan yanÄ±tlamak DEÄÄ°LDÄ°R. Bunun yerine, saÄŸlanan BELGELER'e ve konuÅŸma geÃ§miÅŸine dayanarak, kullanÄ±cÄ±yÄ± cevabÄ± kendi kendine bulmaya yÃ¶neltecek bir tane derin ve yol gÃ¶sterici soru sormaktÄ±r.
BELGELER:
{context}
KULLANICININ SON Ä°LGÄ° ALANI/SORUSU:
{query}
SOKRATÄ°K SORU:"""

quiz_generator_prompt = """{chat_history}
Sen bir sÄ±nav hazÄ±rlama uzmanÄ±sÄ±n. GÃ¶revin, saÄŸlanan BELGELER'e dayanarak, kullanÄ±cÄ±nÄ±n belirttiÄŸi son konuyla ilgili aÅŸaÄŸÄ±daki formatta sÄ±nav sorularÄ± hazÄ±rlamaktÄ±r:

- 4 adet, 4 ÅŸÄ±klÄ± ve tek doÄŸru cevaba sahip Ã§oktan seÃ§meli test sorusu oluÅŸtur. ÅÄ±klar A) B) C) D) olup alt alta sÄ±rasÄ±yla yaz.
- 4 adet boÅŸluk doldurma sorusu oluÅŸtur.
- 4 adet doÄŸru/yanlÄ±ÅŸ sorusu oluÅŸtur.

Her soru, tamamen saÄŸlanan BELGELER'e dayalÄ± olmalÄ± ve aÃ§Ä±k, anlaÅŸÄ±lÄ±r ÅŸekilde yazÄ±lmalÄ±.

CevabÄ±nÄ±n en sonunda, her bir sorunun doÄŸru cevabÄ±nÄ± ve gerekirse Ã§ok kÄ±sa bir aÃ§Ä±klamasÄ±nÄ± iÃ§eren bir cevap anahtarÄ± oluÅŸtur.

BELGELER:
{context}
SINAV KONUSU:
{query}
SINAV SORULARI:
"""

summarizer_prompt = """{chat_history}
Sen bir metin Ã¶zetleme uzmanÄ±sÄ±n. GÃ¶revin, saÄŸlanan BELGELER'e dayanarak kullanÄ±cÄ±nÄ±n belirttiÄŸi son konu hakkÄ±nda anlaÅŸÄ±lÄ±r bir Ã¶zet hazÄ±rlamaktÄ±r.
BELGELER:
{context}
Ã–ZETLENECEK KONU:
{query}
Ã–ZET:"""

# ğŸ” YENÄ°: simulation_prompt â€“ ESKÄ° HALÄ°YLE!
simulation_prompt = """{chat_history}
Sen, sana sunulan belgelerdeki bilgilere dayanarak karmaÅŸÄ±k senaryolarÄ± analiz eden ve vaka Ã§alÄ±ÅŸmalarÄ± yÃ¼rÃ¼ten bir simÃ¼lasyon uzmanÄ±sÄ±n. 
GÃ¶revin, kullanÄ±cÄ±nÄ±n verdiÄŸi 'SENARYO/KOMUT'u, SADECE ve SADECE 'BELGELER' bÃ¶lÃ¼mÃ¼ndeki verileri kullanarak canlandÄ±rmak ve analiz etmektir. 
Belgelerde olmayan hiÃ§bir bilgiyi varsayma veya dÄ±ÅŸarÄ±dan ekleme. MantÄ±ksal Ã§Ä±karÄ±mlar yaparken dayanak noktanÄ± belgelerden gÃ¶stermelisin. 
Bir rolÃ¼ canlandÄ±rÄ±yorsan, o rolÃ¼n aÄŸzÄ±ndan konuÅŸ. Bir analiz yapÄ±yorsan, adÄ±m adÄ±m dÃ¼ÅŸÃ¼nerek bulgularÄ±nÄ± sun.

BELGELER:
{context}

SENARYO/KOMUT:
{query}

SÄ°MÃœLASYON Ã‡IKTISI:"""

mind_mapper_prompt = """{chat_history}
Sen, metinleri analiz ederek kavramlar arasÄ± iliÅŸkileri bulan bir konsept analiz uzmanÄ±sÄ±n.

- Ã–ncelikli gÃ¶revin, aÅŸaÄŸÄ±da verilen BELGELER'den, kullanÄ±cÄ±nÄ±n belirttiÄŸi 'ANA KONU' etrafÄ±nda temel kavramlarÄ± ve bunlarÄ±n birbirleriyle olan iliÅŸkilerini tespit etmektir.
- Sadece BELGELER'deki bilgilere dayanarak, geÃ§erli bir Mermaid.js kodu Ã¼ret.
- Ã‡Ä±ktÄ±n SADECE geÃ§erli bir Mermaid.js kodu olmalÄ±, ek aÃ§Ä±klama veya yorum iÃ§ermemeli.
- CevabÄ±nÄ±n en altÄ±na ÅŸu yÃ¶nlendirme metnini mutlaka ekle:
"Kavram haritasÄ±nÄ± gÃ¶rmek iÃ§in: https://mermaid.live/ adresine gidin ve yukarÄ±daki cevabÄ± eksiksiz ÅŸekilde 'Code' bÃ¶lÃ¼mÃ¼ne yapÄ±ÅŸtÄ±rÄ±n."

BELGELER:
{context}
ANA KONU:
{query}
MERMAID.JSÂ KODU:
"""

# --- DÃ¼ÄŸÃ¼m FonksiyonlarÄ± ---
def direct_answer_node(state: AgentState): return base_agent_node(state, direct_answer_prompt)
def socratic_questioner_node(state: AgentState): return base_agent_node(state, socratic_questioner_prompt)
def quiz_generator_node(state: AgentState): return base_agent_node(state, quiz_generator_prompt)
def summarizer_node(state: AgentState): return base_agent_node(state, summarizer_prompt)
def simulation_node(state: AgentState): return base_agent_node(state, simulation_prompt)
def mind_mapper_node(state: AgentState): return base_agent_node(state, mind_mapper_prompt)
